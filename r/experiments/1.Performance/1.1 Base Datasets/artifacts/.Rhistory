m
}
# MUVR
# https://academic.oup.com/bioinformatics/article/35/6/972/5085367#132378814
muvr_model <- train.MUVR(train)
pred <- predict(muvr_model$Fit$rfFitMax, test, type="prob")[,2]
train.MUVR <- function(train) {
library(MUVR)
nRep = 5
nOuter = 10
varRatio=0.8
method="RF"
m <- MUVR(X=train[5:ncol(train)],
Y=train$SL,
nRep = nRep,
nOuter=nOuter,
varRatio = varRatio,
method = method,
methParam = list(ntreeOut = 1000))
m
}
# MUVR
# https://academic.oup.com/bioinformatics/article/35/6/972/5085367#132378814
muvr_model <- train.MUVR(train)
list(ntreeOut = 1000)
c(ntreeOut = 1000)
train.MUVR <- function(train) {
library(MUVR)
nRep = 5
nOuter = 10
varRatio=0.8
method="RF"
m <- MUVR(X=train[5:ncol(train)],
Y=train$SL,
nRep = nRep,
nOuter=nOuter,
varRatio = varRatio,
method = method,
methParam = c(ntreeOut = 1000))
m
}
# MUVR
# https://academic.oup.com/bioinformatics/article/35/6/972/5085367#132378814
muvr_model <- train.MUVR(train)
train.MUVR <- function(train) {
library(MUVR)
nRep = 5
nOuter = 10
varRatio=0.8
method="RF"
m <- MUVR(X=train[5:ncol(train)],
Y=train$SL,
nRep = nRep,
nOuter=nOuter,
varRatio = varRatio,
method = method)
m
}
# MUVR
# https://academic.oup.com/bioinformatics/article/35/6/972/5085367#132378814
muvr_model <- train.MUVR(train)
train.MUVR <- function(train) {
library(MUVR)
nRep = 5
nOuter = 10
varRatio=0.8
method="RF"
m <- MUVR(X=train[5:ncol(train)],
Y=train$SL,
nRep = nRep,
nOuter=nOuter,
varRatio = varRatio,
method = method,
methParam = c(ntreeOut = 1000))
m
}
summary(muvr_model)
summary(muvr_model$Fit$rfFitMax)
print(muvr_model$Fit$rfFitMax)
train.MUVR <- function(train) {
library(MUVR)
nRep = 5
nOuter = 10
varRatio=0.8
method="RF"
m <- MUVR(X=train[5:ncol(train)],
Y=train$SL,
nRep = nRep,
nOuter=nOuter,
varRatio = varRatio,
method = method,
methParam = list(ntreeIn=150,ntreeOut=1000,mtryMaxIn=150))
m
}
# MUVR
# https://academic.oup.com/bioinformatics/article/35/6/972/5085367#132378814
muvr_model <- train.MUVR(train)
?randomForest
print(muvr_model$Fit$rfFitMax)
params(muvr_model$Fit$rfFitMax)
coef(muvr_model$Fit$rfFitMax)
muvr_model$Fit$rfFitMax$ntree
muvr_model$Fit$rfFitMax$inbag
muvr_model$Fit$rfFitMax$call
muvr_model$Fit$rfFitMax$type
muvr_model$Fit$rfFitMax$predicted
muvr_model$Fit$rfFitMax$classes
muvr_model$Fit$rfFitMax$localImportance
muvr_model$Fit$rfFitMax$forest$maxcat
muvr_model$Fit$rfFitMax$forest$ndbigtree
muvr_model$Fit$rfFitMax$forest$nodestatus
muvr_model$Fit$rfFitMax$forest$bestvar
muvr_model$Fit$rfFitMax$forest$treemap
muvr_model$Fit$rfFitMax$forest$ntree
muvr_model$Fit$rfFitMax$forest$cutoff
muvr_model$Fit$rfFitMax$forest$xlevels
train.rf <- function(train, f){
train.control <- trainControl(
method="repeatedcv",
number=10,
repeats=5,
classProbs=TRUE,
summaryFunction=twoClassSummary,
verboseIter = TRUE
)
train.grid <- expand.grid(mtry = (3:12))
m <- caret::train(f
, data = train
, method = "rf"
, tuneLength = 10
, metric = train.get_metric()
, ntree = 1000
, trControl = train.control
, tuneGrid = train.grid)
return(m)
}
# Random Forest
rf_model <- train.rf(train, f)
pred <- predict(rf_model, test, type = "prob")[, 2]
roc.curve(scores.class0 = pred, weights.class0 = labels[[1]])
?randomForest
train.rf <- function(train, f){
cv_folds <- createFolds(train$SL, k = 10, returnTrain = TRUE)
train.control <- trainControl(
method="cv",
number=10,
classProbs=TRUE,
index=cv_folds,
summaryFunction=twoClassSummary,
verboseIter = TRUE
)
train.grid <- expand.grid(mtry = (3:12))
ntrees <- c(1000)
nodesize <- c(1, 5)
params <- expand.grid(ntrees = ntrees,
nodesize = nodesize)
store_maxnode <- vector("list", nrow(params))
for(i in 1:nrow(params)){
nodesize <- params[i,2]
ntree <- params[i,1]
set.seed(65)
m <- caret::train(f
, data = train
, method = "rf"
, tuneLength = 10
, metric = train.get_metric()
, ntree = 1000
, trControl = train.control
, tuneGrid = train.grid)
store_maxnode[[i]] <- m
}
results_mtry <- resamples(store_maxnode)
summary(results_mtry)
lapply(store_maxnode, print)
return(store_maxnode)
}
# Random Forest
rf_model <- train.rf(train, f)
train.rf <- function(train, f){
cv_folds <- createFolds(train$SL, k = 10, returnTrain = TRUE)
train.control <- trainControl(
method="cv",
number=10,
classProbs=TRUE,
index=cv_folds,
summaryFunction=twoClassSummary,
verboseIter = TRUE
)
train.grid <- expand.grid(mtry = (3:12))
ntrees <- c(1000)
nodesize <- c(1, 5)
params <- expand.grid(ntrees = ntrees,
nodesize = nodesize)
store_maxnode <- vector("list", nrow(params))
for(i in 1:nrow(params)){
nodesize <- params[i,2]
ntree <- params[i,1]
set.seed(65)
m <- caret::train(f
, data = train
, method = "rf"
, tuneLength = 10
, metric = train.get_metric()
, trControl = train.control
, tuneGrid = train.grid)
store_maxnode[[i]] <- m
}
results_mtry <- resamples(store_maxnode)
summary(results_mtry)
lapply(store_maxnode, print)
return(store_maxnode)
}
# Random Forest
rf_model <- train.rf(train, f)
train.rf <- function(train, f){
cv_folds <- createFolds(train$SL, k = 10, returnTrain = TRUE)
train.control <- trainControl(
method="cv",
number=10,
classProbs=TRUE,
index=cv_folds,
summaryFunction=twoClassSummary,
verboseIter = TRUE
)
train.grid <- expand.grid(mtry = (3:12))
ntrees <- c(1000)
nodesize <- c(1, 5)
params <- expand.grid(ntrees = ntrees,
nodesize = nodesize)
store_maxnode <- vector("list", nrow(params))
for(i in 1:nrow(params)){
nodesize <- params[i,2]
ntree <- params[i,1]
set.seed(65)
m <- caret::train(f
, data = train
, method = "rf"
, tuneLength = 10
, metric = train.get_metric()
, trControl = train.control
, tuneGrid = train.grid
, ntree = ntree
, nodesize = nodesize)
store_maxnode[[i]] <- m
}
results_mtry <- resamples(store_maxnode)
summary(results_mtry)
lapply(store_maxnode, print)
return(store_maxnode)
}
# Random Forest
rf_model <- train.rf(train, f)
cv_folds <- createFolds(train$SL, k = 10, returnTrain = TRUE)
train.control <- trainControl(
method="cv",
number=10,
classProbs=TRUE,
index=cv_folds,
summaryFunction=twoClassSummary,
verboseIter = TRUE
)
train.grid <- expand.grid(mtry = (3:12))
ntrees <- c(1000)
nodesize <- c(1, 5)
params <- expand.grid(ntrees = ntrees,
nodesize = nodesize)
store_maxnode <- vector("list", nrow(params))
params
i <- 1
nodesize <- params[i,2]
ntree <- params[i,1]
set.seed(65)
m <- caret::train(f
, data = train
, method = "rf"
, tuneLength = 10
, metric = train.get_metric()
, trControl = train.control
, tuneGrid = train.grid
, ntree = ntree
, nodesize = nodesize)
i <- 2
for(i in 1:nrow(params)){
nodesize <- params[i,2]
ntree <- params[i,1]
set.seed(65)
m <- caret::train(f
, data = train
, method = "rf"
, tuneLength = 10
, metric = train.get_metric()
, trControl = train.control
, tuneGrid = train.grid
, ntree = ntree
, nodesize = nodesize)
store_maxnode[[i]] <- m
}
i <- 2
nodesize <- params[i,2]
ntree <- params[i,1]
set.seed(65)
nodesize
ntree
m <- caret::train(f
, data = train
, method = "rf"
, tuneLength = 10
, metric = train.get_metric()
, trControl = train.control
, tuneGrid = train.grid
, ntree = ntree
, nodesize = nodesize)
store_maxnode[[i]] <- m
results_mtry <- resamples(store_maxnode)
m
lapply(store_maxnode, print)
1:nrow(params)
for(i in 1:nrow(params)){
nodesize <- params[i,2]
ntree <- params[i,1]
set.seed(65)
m <- caret::train(f
, data = train
, method = "rf"
, tuneLength = 10
, metric = train.get_metric()
, trControl = train.control
, tuneGrid = train.grid
, ntree = ntree
, nodesize = nodesize)
store_maxnode[[i]] <- m
}
i <- 1
nodesize <- params[i,2]
ntree <- params[i,1]
set.seed(65)
m <- caret::train(f
, data = train
, method = "rf"
, tuneLength = 10
, metric = train.get_metric()
, trControl = train.control
, tuneGrid = train.grid
, ntree = ntree
, nodesize = nodesize)
store_maxnode[[i]] <- m
i <- 2
nodesize <- params[i,2]
ntree <- params[i,1]
set.seed(65)
m <- caret::train(f
, data = train
, method = "rf"
, tuneLength = 10
, metric = train.get_metric()
, trControl = train.control
, tuneGrid = train.grid
, ntree = ntree
, nodesize = nodesize)
store_maxnode[[i]] <- m
nodesize <- params[i,2]
ntree <- params[i,1]
set.seed(65)
m <- caret::train(f
, data = train
, method = "rf"
, tuneLength = 10
, metric = train.get_metric()
, trControl = train.control
, tuneGrid = train.grid
, ntree = ntree
, nodesize = nodesize)
store_maxnode[[i]] <- m
lapply(store_maxnode, print)
install.packages("RRF")
seq(0,1,0.1)
?RRF
library(RRF)
?RRF
rf <- RRF(f, data = train, flagReg = 0)
impRF <- rf$importance
impRF <- impRF[,"MeanDecreaseGini"]
rf$feaSet
imp <- impRF/(max(impRF))#normalize the importance score
gamma <- 0.5
coefReg <- (1-gamma)+gamma*imp #weighted average
coefReg
rf <- rrfcv(f, data = train, cv.fold = 5)
?createFolds
cv_folds <- createFolds(train$SL, k = 10)
cv_folds <- createFolds(train$SL, k = 10)
train.control <- trainControl(
method="repeatedcv",
number=10,
repeats=5,
classProbs=TRUE,
index = cv_folds,
summaryFunction=twoClassSummary,
verboseIter = TRUE
)
train.grid <- expand.grid(mtry = (3:12))
rf <- caret::train(f
, data = train
, method = "rf"
, metric = train.get_metric()
, trControl = train.control
, ntree = 700,
, tuneGrid = train.grid)
rf <- caret::train(f
, data = train
, method = "rf"
, metric = train.get_metric()
, trControl = train.control
, ntree = 700
, tuneGrid = train.grid)
impRF <- rf$importance
impRF
rf$finalModel$importance
?caret::train
train.control <- trainControl(
method="repeatedcv",
number=10,
repeats=5,
classProbs=TRUE,
summaryFunction=twoClassSummary,
verboseIter = TRUE
)
train.grid <- expand.grid(
mtry = (3:12),
coefReg = seq(0,1,0.1)
)
m <- caret::train(f
, data = train
, method = "RRF"
, tuneLength = 10
, metric = train.get_metric()
, trControl = train.control
, tuneGrid = train.grid)
0:1
train.grid <- expand.grid(
mtry = (3:12),
coefReg = seq(0,1,0.1),
coefImp = 0:1
)
train.control <- trainControl(
method="repeatedcv",
number=10,
repeats=5,
classProbs=TRUE,
summaryFunction=twoClassSummary,
verboseIter = TRUE
)
train.grid <- expand.grid(
mtry = (3:12),
coefReg = seq(0,1,0.1)
)
m <- caret::train(f
, data = train
, method = "RRFglobal"
, tuneLength = 10
, metric = train.get_metric()
, trControl = train.control
, tuneGrid = train.grid)
train.control <- trainControl(
method="repeatedcv",
number=10,
repeats=5,
classProbs=TRUE,
summaryFunction=twoClassSummary,
verboseIter = TRUE
)
train.grid <- expand.grid(
mtry = (3:12),
coefReg = seq(0,1,0.1)
)
m <- caret::train(f
, data = train
, method = "RRFglobal"
, tuneLength = 10
, metric = train.get_metric()
, trControl = train.control
, tuneGrid = train.grid)
stopCluster(cl)
train.control <- trainControl(
method="repeatedcv",
number=10,
repeats=5,
classProbs=TRUE,
summaryFunction=twoClassSummary,
verboseIter = TRUE
)
train.grid <- expand.grid(
mtry = (4:12),
coefReg = seq(0.5,1,0.1)
)
m <- caret::train(f
, data = train
, method = "RRFglobal"
, metric = train.get_metric()
, trControl = train.control
, tuneGrid = train.grid)
registerDoSEQ()
m <- caret::train(f
, data = train
, method = "RRFglobal"
, metric = train.get_metric()
, trControl = train.control
, tuneGrid = train.grid)
m
m$bestTune
m$finalModel
m$results
